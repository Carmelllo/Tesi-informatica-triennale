\chapter{Descrizione dello stage}
\label{cap:descrizione-stage}
\intro{In questo capitolo viene fornita una panoramica del progetto di stage incentrato sulla sicurezza di AI generativa (OWASP, Gandalf Test), dei rischi e delle mitigazioni, dei requisiti e degli obiettivi, e della pianificazione fino alla produzione di report e dashboard.}\\

\section{Introduzione al progetto}


\section{Analisi preventiva dei rischi}

Durante la fase iniziale di analisi sono stati identificati i principali rischi potenziali connessi al progetto, classificati per ambito (tecnico, di progetto e infrastrutturale) e priorizzati in base all'impatto e alla probabilità. Per ciascun rischio è stato predisposto un piano di mitigazione che definisce azioni concrete, tempistiche e responsabilità precise.

Le contromisure prevedono attività di sperimentazione controllata degli strumenti, revisioni manuali dei risultati, integrazione e test in ambienti rappresentativi, oltre a piani di escalation per le criticità più gravi. È inoltre prevista una procedura di monitoraggio continuo e revisione periodica delle valutazioni e delle soluzioni adottate, in modo da aggiornare rapidamente le contromisure alla luce di nuovi dati o evoluzioni tecnologiche.

\subsection{Rischi tecnici}

\begin{risk}{Complessità nell'applicare strumenti di \emph{security testing} ad AI generativa (\emph{tool} immaturi o
non sempre affidabili).}
    \riskdescription{Le difficoltà nell'adattare i \emph{tool} di \emph{security testing} all'AI generativa possono derivare dalla loro immaturità o dalla mancanza di affidabilità}
    \risksolution{Una lunga fase di sperimentazione e \emph{testing} dei \emph{tool} ha mitigato i rischi, garantendo risultati affidabili}
\end{risk}

\begin{risk}{Possibili falsi positivi o negativi nei \emph{test} di vulnerabilità.}
    \riskdescription{I \emph{test} di vulnerabilità potrebbero generare risultati inaccurati, con falsi positivi (segnalazioni errate di vulnerabilità) o falsi negativi (mancata rilevazione di vulnerabilità reali)}
    \risksolution{Implementare una fase di revisione manuale dei risultati dei \emph{test} per convalidare le segnalazioni e ridurre il rischio di falsi positivi e negativi}
\end{risk}

\begin{risk}{Difficoltà di integrazione dei \emph{tool} con codice reale e \gls{pipeline}\glsfirstoccur di sviluppo.}
    \riskdescription{Le difficoltà di integrazione possono derivare da incompatibilità tra i \emph{tool} di \emph{testing} e l'infrastruttura esistente, nonché dalla complessità del codice reale su cui si stanno eseguendo i \emph{test}}
    \risksolution{Collaborare con gli sviluppatori del codice reale per garantire che i \emph{tool} di \emph{testing} siano compatibili con l'infrastruttura esistente e fornire supporto durante l'integrazione}
\end{risk}

\subsection{Rischi di progetto}

\begin{risk}{Mancanza di esperienza pregressa su OWASP o sicurezza AI.}
    \riskdescription{La poca familiarità con le \emph{best practice} di OWASP o con le specificità della sicurezza nell'AI generativa potrebbe rallentare l'avanzamento del progetto}
    \risksolution{Studio e formazione con risorse adeguate per aumentare la familiarità con OWASP e la sicurezza dell'AI generativa}
\end{risk}

\begin{risk}{Possibile difficoltà a rispettare la pianificazione a causa della curva di apprendimento iniziale.}
    \riskdescription{La curva di apprendimento iniziale per l'utilizzo di nuovi strumenti e tecnologie potrebbe richiedere più tempo del previsto, influenzando la pianificazione del progetto}
    \risksolution{Pianificazione di margini di tempo aggiuntivi per la formazione e l'adattamento agli strumenti, nonché monitoraggio attento dei progressi}
\end{risk}

\subsection{Rischi infrastrutturali}

\begin{risk}{Limitazioni di risorse computazionali nei \emph{test} di AI.}
    \riskdescription{Le risorse computazionali disponibili per l'esecuzione dei \emph{test} di AI potrebbero non essere sufficienti, causando rallentamenti o interruzioni nei \emph{test}}
    \risksolution{Ottimizzazione dell'uso delle risorse disponibili e richiesta di accesso a risorse computazionali aggiuntive}
\end{risk}

\begin{risk}{Problemi di compatibilità con ambienti \emph{cloud} o di \emph{deployment}.}
    \riskdescription{Le differenze tra gli ambienti di sviluppo e produzione potrebbero causare problemi di compatibilità, rendendo difficile l'esecuzione dei \emph{test} in modo uniforme}
    \risksolution{Testare i \emph{tool} di \emph{testing} in ambienti simili a quelli di produzione e documentazione di eventuali problemi di compatibilità}
\end{risk}


\section{Requisiti e obiettivi}


\subsection{Obiettivi obbligatori}
\begin{itemize}
\item Valutazione comparativa degli strumenti di analisi.
\item Applicazione pratica dei test su codice reale.
\item Prototipo in grado di generare report sulle vulnerabilità AI rispetto a OWASP.
\item Documentazione tecnica e presentazione finale.
\end{itemize}

\subsection{Obiettivi desiderabili}
\begin{itemize}
\item \emph{Dashboard} interattiva con visualizzazioni avanzate
\item Integrazione del prototipo in \emph{pipeline} \gls{cicd}\glsfirstoccur esistente.
\item Estensione dei \emph{test} ad altri \emph{framework} oltre \gls{gandalf-test}\glsfirstoccur.
\item Raccomandazioni per un \emph{framework} interno di AI \emph{Security by Design}.
\end{itemize}

\section{Pianificazione}

La pianificazione del lavoro di progetto è stata suddivisa in fasi settimanali, con obiettivi specifici per ciascuna fase. Di seguito è riportata una panoramica della pianificazione prevista:

\begin{table}[htbp]
    \centering
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{|p{3cm}|p{10cm}|}
        \hline
        \textbf{Settimana} & \textbf{Attività} \\
        \hline
        Settimana 1 & Studio preliminare su OWASP e rischi AI, \emph{overview} di \gls{gandalf-test}, \emph{setup} ambiente di
lavoro.\\
        \hline
        Settimana 2 & Analisi comparativa di \emph{tool} di analisi statica e dinamica (\emph{open source} e commerciali).
Creazione matrice di valutazione.\\
        \hline
        Settimana 3 & Applicazione degli strumenti a piccoli progetti \emph{demo}, valutazione dei risultati e raccolta
criticità.\\
        \hline
        Settimana 4 & Esecuzione dei primi \emph{test} su componenti reali del \emph{team}, documentazione dei risultati,
identificazione vulnerabilità.\\
        \hline
        Settimana 5 & Realizzazione di \emph{script}/\emph{report} per aggregare risultati, definizione dei \gls{kpi}\glsfirstoccur di \emph{compliance}
OWASP.\\
        \hline
        Settimana 6 & Sviluppo di \emph{dashboard} interattiva per monitorare vulnerabilità e andamento dei \emph{test}.\\
        \hline
        Settimana 7 & \emph{Test end-to-end} sul prototipo, miglioramento dei \emph{tool} e dei \emph{report}.\newline\mbox{}\\
        \hline
        Settimana 8 & Redazione di documentazione tecnica, manuale utente e materiale per la presentazione
della tesi.\\
        \hline
    \end{tabular}
    \caption{Pianificazione delle attività di progetto}
\end{table}

\subsection{Settimana 1}
Durante la prima settimana di lavoro il \emph{focus} è stato posto sullo studio di OWASP e alla comprensione del ambito di studio del progetto. In questo periodo è stata fatta una estensiva ricerca sulla \emph{top} 10 delle vulnerabilità delle LLM secondo OWASP e dei metodi di \emph{testing}, attacco e \emph{red teaming} più comuni ed efficaci in modo tale da avere una visione completa delle problematiche di sicurezza legate all'AI. Essendo l'ambito di studio in continua evoluzione è stato fondamentale raccogliere informazioni sulle tecnologie più recenti e le metodologie attuali per il \emph{testing} delle vulnerabilità delle LLM. Nei primi giorni della settimana ho avuto modo di provare di persona il \gls{gandalf-test} in modo tale da comprendere a fondo come le LLM possono essere ingannate a rivelare informazioni sensibili (\emph{role play}, uso di lingua differente, richieste implicite, ecc.). Nell'ultima parte della settimana ho approfondito sul concetto di \emph{red teaming} e le sue applicazioni pratiche nel contesto delle LLM poiché ho avuto modo di vedere che molti \emph{tool} di \emph{security testing} per AI generativa si basano su questa metodologia di attacco. A valle della ricognizione iniziale ho mappato le categorie OWASP più rilevanti ai casi d'uso previsti (\emph{prompt injection}, \emph{disclosure} di informazioni sensibili, \emph{hallucination} e \emph{output} non sicuri, uso di \emph{tool} esterni eccessivamente permissivi, \emph{data poisoning}, differenze tra \emph{test} in \emph{black-box} e scenari più informati), cercando di capire come tradurre ciascun rischio in casi di \emph{test} ripetibili. Ho inoltre analizzato la letteratura più recente (\emph{whitepaper}, linee guida e \emph{report} tecnici) per identificare \emph{pattern} ricorrenti di attacco e difesa e per definire un insieme minimo di metriche di valutazione (riproducibilità del \emph{test}, tasso di successo del \gls{jailbreak}\glsfirstoccur, severità dell'impatto, copertura delle categorie OWASP) utile a confrontare approcci manuali e automatizzati.

Sul fronte sperimentale, con il \gls{gandalf-test} ho eseguito più iterazioni variando strategia e contesto per osservare come cambiano le risposte del modello al variare dell'intento e della formulazione (cambio di persona nel \emph{role play}, ricorso a lingue miste, parafrasi progressive, codifiche/decodifiche semplici, richieste spezzate su più turni, evocazione di autorità fittizie o regole alternative). Ho annotato quali tattiche risultano più efficaci e in quali condizioni falliscono (\emph{rate limit}, filtri di sicurezza, memoria contestuale), in modo da derivare linee guida utili alla fase di automazione. Ho iniziato anche a delineare il perimetro etico e di \emph{compliance}, chiarendo i confini del \emph{red teaming} responsabile e le cautele nella gestione di \emph{output} potenzialmente sensibili. Questo lavoro preliminare ha permesso di costruire una base metodologica solida, utile per selezionare in modo informato gli strumenti da valutare nelle settimane successive e per impostare una prima matrice di tracciamento tra rischi OWASP, scenari di \emph{test} e criteri di accettazione.

\subsection{Settimana 2}
Nel corso della seconda settimana di lavoro l'interesse si è concentrato sull'analisi approfondita delle varie tecnologie e \emph{tool} esistenti per il \emph{testing} delle LLM. Ho condotto una ricerca esaustiva per identificare sia soluzioni \emph{open source} che commerciali, valutando ciascuna in base a criteri quali facilità d'uso, capacità di integrazione, copertura delle vulnerabilità OWASP, scalabilità e costi associati. Ho creato una matrice di valutazione comparativa (osservabile nel capitolo \ref{cap:progettazione-codifica}, sezione \ref{sec:tecnologie-strumenti}) per sintetizzare i punti di forza e le limitazioni di ogni strumento, facilitando così la selezione dei candidati più promettenti per le fasi successive del progetto. Durante l'analisi, ho esaminato \emph{tool} come PromptFoo, PyRIT, LangFuse, DeepEval/DeepTeam, Garak, Giskard, Galileo e LakeraGuard, approfondendo le loro funzionalità specifiche per il \emph{security testing} delle LLM. Ho valutato come ciascuno di questi strumenti affronta le principali categorie di vulnerabilità identificate nella settimana precedente, e ho visionato numerosi \emph{talk} e conferenze per comprendere al meglio ogni \emph{tool} sottoposto ad analisi e le loro applicazioni pratiche. Ho creato piccoli \emph{script} per testare alcune delle funzionalità offerte dai \emph{tool}, in modo tale da farmi un'idea più precisa delle loro capacità e limitazioni. Al termine della settimana, ho redatto la matrice di valutazione prima citata la quale servirà come base per la selezione degli strumenti da utilizzare nelle fasi successive del progetto, garantendo che le scelte siano informate e allineate agli obiettivi di sicurezza definiti in precedenza.
\subsection{Settimana 3}
TBA
\subsection{Settimana 4}
TBA
\subsection{Settimana 5}
TBA
\subsection{Settimana 6}
TBA
\subsection{Settimana 7}
TBA
\subsection{Settimana 8}
TBA